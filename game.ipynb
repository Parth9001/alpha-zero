{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TicTacToe:\n",
    "    def __init__(self):\n",
    "        self.board = np.zeros((3, 3), dtype=int)\n",
    "        self.current_player = 1\n",
    "    \n",
    "    def make_move(self, row, col):\n",
    "        if self.board[row, col] == 0:\n",
    "            self.board[row, col] = self.current_player\n",
    "            self.current_player = 3 - self.current_player  # Switch player\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def check_winner(self):\n",
    "        for i in range(3):\n",
    "            if np.all(self.board[i, :] == self.current_player):\n",
    "                return self.current_player\n",
    "            if np.all(self.board[:, i] == self.current_player):\n",
    "                return self.current_player\n",
    "        \n",
    "        if self.board[0, 0] == self.board[1, 1] == self.board[2, 2] == self.current_player:\n",
    "            return self.current_player\n",
    "        \n",
    "        if self.board[0, 2] == self.board[1, 1] == self.board[2, 0] == self.current_player:\n",
    "            return self.current_player\n",
    "        \n",
    "        return 0\n",
    "\n",
    "    def is_draw(self):\n",
    "        return np.all(self.board != 0)\n",
    "\n",
    "    def is_game_over(self):\n",
    "        return self.check_winner() or self.is_draw()\n",
    "\n",
    "    def get_valid_moves(self):\n",
    "        return [(i, j) for i in range(3) for j in range(3) if self.board[i, j] == 0]\n",
    "\n",
    "    def display(self):\n",
    "        print(self.board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride = 1):\n",
    "        super(ResNetBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size = 3, stride = stride, padding = 1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size = 3, padding = 1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size = 1, stride = stride),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=9):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channels = 64\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.fc1 = nn.Linear(128 * 3 * 3, num_classes)\n",
    "        self.fc2 = nn.Linear(128 * 3 * 3, 1) # For winning probability\n",
    "\n",
    "    def _make_layer(self, block, out_channels, num_blocks, stride):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_channels, out_channels, stride))\n",
    "            self.in_channels = out_channels\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = F.adaptive_avg_pool2d(out, (1, 1))\n",
    "        out = out.view(out.size(0), -1)\n",
    "        policy = self.fc1(out)\n",
    "        value = torch.tanh(self.fc2(out))\n",
    "        return policy, value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet18():\n",
    "    return ResNet(ResNetBlock, [2, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCTSNode:\n",
    "    def __init__(self, state, parent=None):\n",
    "        self.state = state\n",
    "        self.parent = parent\n",
    "        self.children = {}\n",
    "        self.visits - 0\n",
    "        self.value = 0.0\n",
    "        self.prior = 0.0\n",
    "\n",
    "    def is_leaf(self):\n",
    "        return len(self.children) == 0\n",
    "    \n",
    "    def expand(self, action_priors):\n",
    "        for action, prior, in action_priors:\n",
    "            self.children[action] = MCTSNode(self.state, parent=self)\n",
    "            self.children[action].prior = prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCTS:\n",
    "    def __init__(self, model, c_puct=1.0, n_playouts=1600):\n",
    "        self.model = model\n",
    "        self.c_puct = c_puct\n",
    "        self.n_playouts = n_playouts\n",
    "\n",
    "    def _uct_select(self, node):\n",
    "        return max(node.children.items(), key=lambda act_node: act_node[1].value/(1 + act_node[1].visits) + self.c_puct * act_node[1].prior * math.sqrt(node.visits) / (1 + act_node[1].visits))\n",
    "    \n",
    "    def _playout(self, state):\n",
    "        node = self.root\n",
    "        while not node.is_leaf():\n",
    "            action, node = self._uct_select(node)\n",
    "            state.make_move(*action)\n",
    "        action_probs, _ = self.model(torch.FloatTensor(state.board).unsqueeze(0).unsqueeze(0))\n",
    "        action_probs = torch.softmax(action_probs, dim=1).detach().numpy().flatten()\n",
    "        valid_moves = state.get_valid_moves()\n",
    "        action_priors = [(move, action_probs[i]) for i, move in enumerate(valid_moves)]\n",
    "        node.expand(action_priors) \n",
    "\n",
    "        leaf_value = self._evaluate(state)\n",
    "        self._backpropagate(node, leaf_value)\n",
    "\n",
    "    def _evaluate(self, state):\n",
    "        _, value = self.model(torch.FloatTensor(state.board).unsqueeze(0).unsqueeze(0))\n",
    "        return value.item()\n",
    "    \n",
    "    def _backpropagate(self, node, value):\n",
    "        while node:\n",
    "            node.visits += 1\n",
    "            node.value += value\n",
    "            node = node.parent\n",
    "\n",
    "    def get_move(self, state):\n",
    "        self.root = MCTSNode(state)\n",
    "        for _ in range(self.n_playouts):\n",
    "            self._playout(state)\n",
    "        return max(self.root.children.items(), key=lambda act_node: act_node[1].visits)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def self_play(game, model, mcts, n_games=1000):\n",
    "    data = []\n",
    "    for _ in range(n_games):\n",
    "        state = game()\n",
    "        while not state.is_game_over():\n",
    "            move = mcts.get_move(state)\n",
    "            data.append((state.board.copy(), move))\n",
    "            state.make_move(*move)\n",
    "        winner = state.check_winner()\n",
    "        for board, move in data:\n",
    "            if winner == state.current_player:\n",
    "                reward = 1\n",
    "            elif winner == 0:\n",
    "                reward = 0\n",
    "            else: \n",
    "                reward = -1\n",
    "            yield board, move, reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, game, mcts, n_games=1000):\n",
    "    model.train()\n",
    "    for board, move, reward in self_play(game, model, mcts, n_games):\n",
    "        optimizer.zero_grad()\n",
    "        board = torch.FloatTensor(board).unsqueeze(0).unsqueeze(0)\n",
    "        policy, value = model(board)\n",
    "        loss = F.mse_loss(value, torch.FloatTensor([reward])) + F.cross_entropy(policy, torch.LongTensor([move]))\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3417958533728861eeac5d2cbd3320613748a2616df8deaeec72181b61d05632"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
